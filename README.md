Cyndi Operator
===========================================

This is an Openshift operator. The project's scaffolding was generated by the 
[operator-sdk v0.19](https://v0-19-x.sdk.operatorframework.io/docs/golang/quickstart/). At a high level,
it manages the Kafka Connector and DB table for an application's Cyndi pipeline. This includes creating the connector
and DB table, validating the data is syndicated correctly, and automatically refreshing the pipeline when the data
becomes out of sync.

## Development 
`TODO`

## Typical Flows

#### Create a new pipeline

1. Set the PipelineVersion to the current timestamp
1. Create a new table in AppDB (e.g. inventory.hosts_v1_1597073300783716678)
1. Create a new Kafka Sink Connector pointing to the new table
1. Attempt to validate the data is in sync. Each time the validation fails, it will requeue the reconcile loop until
validation succeeds, or the retry limit is reached. If the retry limit is reached before validation succeeds, the 
existing table and connector will be deleted, and the pipeline will be recreated starting at step 1.
1. After validation succeeds, the DB view (inventory.hosts) will be updated to point to the new table.
1. The reconcile loop will be re-queued to run periodically to validate the data is in sync.

#### Delete a pipeline
`TODO`

#### Refresh an out of sync pipeline
`TODO`

#### Migrate an existing pipeline to a new schema
`TODO`

## Other Notes

#### Validation Criteria
`TODO`

#### Connector Config
`TODO`

#### Database Schema
`TODO`

#### Database Connection Details
`TODO`
